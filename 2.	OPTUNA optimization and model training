import pandas as pd
import numpy as np
import lightgbm as lgb
import optuna
from sklearn import metrics
from lightgbm import log_evaluation, early_stopping
from sklearn.model_selection import train_test_split, KFold
from sklearn.metrics import mean_squared_error


train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)

def objective(trial):

    dtrain = lgb.Dataset(train_x, label=train_y, categorical_feature=columns)
    param = {
        'metric': 'rmse',
        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),
        'learning_rate': trial.suggest_categorical('learning_rate', [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]),
        'n_estimators': trial.suggest_int('n_estimators', 50, 500, 1),
        'max_depth': trial.suggest_int('max_depth', 1, 40, 1),
        'random_state': 42
    }
    model = LGBMRegressor(**param)
    callbacks = [log_evaluation(period=30), early_stopping(stopping_rounds=100)]

    model.fit(train_x, train_y, eval_set=[(test_x, test_y)], callbacks=callbacks)
    preds = model.predict(test_x)
    mse = mean_squared_error(test_y, preds, squared=False)
    return mse


study = optuna.create_study(direction='minimize')
n_trials = 300 
study.optimize(objective, n_trials=n_trials)
print('Number of finished trials:', len(study.trials))
print("------------------------------------------------")
print('Best trial:', study.best_trial.params)
print("------------------------------------------------")
print(study.trials_dataframe())
print("------------------------------------------------")

params = study.best_params
params['metric'] = 'mse'

# optimization_history
optuna.visualization.matplotlib.plot_optimization_history(study)

# parallel_coordinate
optuna.visualization.matplotlib.plot_parallel_coordinate(study)

# plot_slice
optuna.visualization.matplotlib.plot_slice(study)

# countour plots
optuna.visualization.matplotlib.plot_contour(study, params=[
                            'max_depth',
                            # 'lambda',
                            'subsample',
                            'learning_rate',
                            'subsample'])

# plot_param_importances
optuna.visualization.matplotlib.plot_param_importances(study)

# plot_edf
optuna.visualization.matplotlib.plot_edf(study)
plt.show()

# Model training and development
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

params_lgb = {n_estimators=params['n_estimators'],
                          max_depth=params['max_depth'],
                          learning_rate=params['learning_rate'],
                          subsample=params['subsample'],
                          random_state=42
}

kf = KFold(n_splits=5, shuffle=True, random_state=42)
scores = []
best_score = np.inf
best_model = None

for fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train)):
    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]
    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]

    model = lgb.LGBMRegressor(**params_lgb)

    model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold))

    y_val_pred = model.predict(X_val_fold)
    score = mean_squared_error(y_val_fold, y_val_pred)

    scores.append(score)
    print(f' {fold + 1} CV RMSE: {score}')

    if score < best_score:
        best_score = score
        best_model = model

print(f'the best RMSE: {best_score}')

y_pred_four = best_model.predict(X_test)

y_pred_list = y_pred_four.tolist()
mse = metrics.mean_squared_error(y_test, y_pred_list)
rmse = np.sqrt(mse)
mae = metrics.mean_absolute_error(y_test, y_pred_list)
r2 = metrics.r2_score(y_test, y_pred_list)

print("MSE:", mse)
print("RMSE:", rmse)
print("MAE:", mae)
print("R-squared:", r2)
